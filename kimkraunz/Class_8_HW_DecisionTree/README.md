 __Kim Kraunz__
# Class 8 Homework - Naive Bayes, Decision Trees, and Classification Model Evaluation


## Introduction
I used the Lahman Baseball Database for all analysis. In this homework I built Naive Bayes and Decision Tree models to predict Hall of Fame induction on those inducted before 2000.  I compared the models using the 10-fold cross-validated accuracy, Cohen's Kappa, and F1 scores and compared it to the KNN model from HW 5.  Lastly, I printed out the confusion matrix and 10-fold cross-validation ROC scores.

I used the following code to pull the total salaries and total runs grouped by year from the SQLite database.

```
import pandas
import numpy
import sqlite3
from sklearn.naive_bayes import MultinomialNB
from sklearn.cross_validation import cross_val_score

# import sql data
conn = sqlite3.connect('/Users/jkraunz/Documents/SQLite/lahman2013.sqlite.crdownload')

sql = '''
Select d.*, sum(H) as total_post_hits, sum(HR) as total_post_HRs, sum(RBI) as total_post_RBIs
FROM
(Select c.*, sum(W) as total_post_wins, sum(SV) as total_post_saves, avg(ERA) as avg_post_ERA
FROM
(Select a.*, sum(E) as total_errors
FROM
(SELECT m.*,
sum(SO) as total_SOs, avg(ERA) as avg_ERA, sum(W) as total_wins, sum(SV) as total_saves, count(YearID) as years_pitched
FROM
(select h.*, sum(RBI) as total_RBIs, sum(SB) as total_stolen_bases, sum(BB) as total_walks,
sum(R) as total_runs, sum(H) as total_hits, count(yearID) as years_batted, sum(HR) as total_HRs, sum('2B') as total_2B, sum('3B') as total_3B
FROM 
(SELECT playerID, max(yearID) as final_year_voted, count(yearID) as years_voted, inducted
FROM HallofFame 
Where yearID < 2000
GROUP BY playerID) h
LEFT JOIN Batting b on h.playerID = b.playerID
GROUP BY h.playerID) m
LEFT JOIN Pitching p on m.playerID = p.playerID
group by m.playerID) a
LEFT JOIN Fielding f on a.playerID = f.playerID
GROUP BY a.playerID) c
Left Join PitchingPost pp on c.playerID = pp.playerID
GROUP BY c.playerID) d
Left Join BattingPost bp on d.playerID = bp.playerID
Group By d.playerID
'''

df = pandas.read_sql(sql, conn)

conn.close()
```

I cleaned up the imported data.

```
df.head()
pandas.set_option('display.max_columns', None)
df.head()

df.describe()

df.dropna(how = 'all', inplace = True)

df['inducted1'] = 0
df.inducted1[df.inducted == 'Y'] = 1

df['years_played'] = 0
df.years_played[df.years_pitched >= df.years_batted] = df.years_pitched
df.years_played[df.years_pitched < df.years_batted] = df.years_batted

df.drop(['playerID', 'inducted', 'years_pitched', 'years_batted', 'final_year_voted'],  1, inplace = True)

df.head(10)
df.describe()
```

I set up the explanatory and reponse variables.
```
explanatory_features = [col for col in df.columns if col not in ['inducted1']]
explanatory_df = df[explanatory_features]

explanatory_df.head()

explanatory_col_names = explanatory_df.columns

response_series = df.inducted1

response_series.index[~response_series.index.isin(explanatory_df.index)]
```

I replaced the NaNs with column means.
```
from sklearn.preprocessing import Imputer
imputer_object = Imputer(missing_values='NaN', strategy='mean', axis=0)

imputer_object.fit(explanatory_df)
explanatory_df = imputer_object.transform(explanatory_df)
```

####Naive Bayes
I ran the Naive Bayes model on the data to see whether it was a good model to use for predicting Hall of Fame inducation.  I then printed out a confusion matrix for the model generated by splitting the data into training and testing groups.

```
naive_bayes_classifier = MultinomialNB()

# Confusion matrix

from sklearn.cross_validation import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(
                    explanatory_df, response_series, test_size =  0.3)

# get predictions on the test group 
y_predicted = naive_bayes_classifier.fit(xTrain, yTrain).predict(xTest)

cm = pandas.crosstab(yTest, y_predicted, rownames=['True Label'], colnames=['Predicted Label'], margins=True)

print cm

Predicted Label    0    1  All
True Label                    
0                132   84  216
1                 17   52   69
All              149  136  285

```
From the confusion matrix, I determined the sensitivity and specificity.

sensitivity = 52/(17+52) = 75%

specificity = 132/(132+84) = 61%

Neither of those are stellar.  The model is almost equally as bad at classifying those that are inducted as not inducted and those that are not inducted as being inducted.


####Model Evaluation
I then evaluated the strength of the model based on 10-fold cross-validated accuracy, Cohen's Kappa, F1, and ROC scores.

```
# Accuracy
accuracy_scores = cross_val_score(naive_bayes_classifier, explanatory_df, response_series, cv=10, scoring = 'accuracy', n_jobs = -1)

print accuracy_scores.mean()

# Cohen's Kappa
mean_accuracy_score = accuracy_scores.mean()
largest_class_percent_of_total = response_series.value_counts(normalize = True)[0]

kappa = (mean_accuracy_score - largest_class_percent_of_total) / (1 - largest_class_percent_of_total) 
print kappa


# F1 scores
f1_scores = cross_val_score(naive_bayes_classifier, explanatory_df, response_series, cv = 10, scoring = 'f1', n_jobs = -1)

print f1_scores.mean()

# Roc scores
roc_scores = cross_val_score(naive_bayes_classifier, explanatory_df, response_series, cv = 10, scoring = 'roc_auc', n_jobs = 01)

print roc_scores.mean()
```

The model was 61% accurate, had a Cohen's Kappa of -0.710 (yikes!), an F1 score of .457 (shows the lack of specificity and sensitivity), and a ROC score of .618 (defined as fair).  Naive Bayes does not seem to be a good predictor of Hall of Fame induction with this data.


####Decision Tree
```
from sklearn import tree

decision_tree = tree.DecisionTreeClassifier(random_state=1)

decision_tree.fit(xTrain, yTrain)
```
I then created a confusion matrix.

```
# Confusion matrix
predicted_values = decision_tree.predict(xTest)

cm = pandas.crosstab(yTest, predicted_values, rownames=['True Label'], colnames=['Predicted Label'], margins=True)

print cm

Predicted Label    0   1  All
True Label                   
0                198  18  216
1                 22  47   69
All              220  65  285
```

The sensitivity for the Decision Tree model is 47/(22 + 47) = 68%

The specificity is 198/(198 + 18) = 92%

The sensitivity dropped but the specificity increased dramatically as compared to the Naive Bayes model.

I wanted to look at the importance of each feature.

```
# Finds the importances of each feature
importances_df = pandas.DataFrame(explanatory_col_names)
importances_df['importances'] = decision_tree.feature_importances_

print importances_df

                     0  importances
0          years_voted     0.121452
1           total_RBIs     0.028669
2   total_stolen_bases     0.014806
3          total_walks     0.034252
4           total_runs     0.168654
5           total_hits     0.069967
6            total_HRs     0.042953
7             total_2B     0.007707
8             total_3B     0.047686
9            total_SOs     0.030915
10             avg_ERA     0.009279
11          total_wins     0.127742
12         total_saves     0.016019
13        total_errors     0.066285
14     total_post_wins     0.000000
15    total_post_saves     0.000000
16        avg_post_ERA     0.009568
17     total_post_hits     0.012995
18      total_post_HRs     0.030511
19     total_post_RBIs     0.006014
20        years_played     0.154525
```

I see that years_voted, total_RBIs, and total_stolen_bases are the features with the highest importances.

####Model Evaluation
I then used accuracy, Cohen's Kappa, F1, and ROC scores to compare the Naive Bayes to the Decision Tree model.

```
# Accuracy
accuracy_scores_cart = cross_val_score(decision_tree, explanatory_df, response_series, cv=10, scoring='accuracy', n_jobs = -1)

print accuracy_scores_cart.mean()
print accuracy_scores.mean()

0.830123180291
0.606662933931

# Cohen's Kappa
mean_accuracy_score_cart = accuracy_scores_cart.mean()

kappa_cart = (mean_accuracy_score_cart - largest_class_percent_of_total) / (1-largest_class_percent_of_total)

print kappa_cart
print kappa

0.261269609706
-0.710474947862

# F1 score
f1_scores_cart = cross_val_score(decision_tree, explanatory_df, response_series, cv=10, scoring='f1', n_jobs = -1)

print f1_scores_cart.mean()
print f1_scores.mean()

0.634868620875
0.456959713712

# ROC
roc_scores_cart = cross_val_score(decision_tree, explanatory_df, response_series, cv=10, scoring='roc_auc', n_jobs = -1)

print roc_scores_cart.mean()
print roc_scores.mean()

0.767430172567
0.617756330428
```

The accuracy of predicting Hall of Fame induction by the Decision Tree model was higher than the accuracy of the Naive Bayes model across all metrics for evaluating models.  However, the Decision Tree model was still not highly accurate.


####K Nearest Neighbor (KNN)

Revisited KNN from HW 5 to compare it's predictive value to the Decision Tree and Naive Bayes models.
```
from sklearn.neighbors import KNeighborsClassifier
from __future__ import division
import matplotlib.pyplot as plt
from sklearn.grid_search import GridSearchCV


KNN = KNeighborsClassifier(p = 2)

KNN.fit(xTrain, yTrain)
```
Printed out the confusion matrix.
```
# Confusion matrix
predicted_values = KNN.predict(xTest)

cm = pandas.crosstab(yTest, predicted_values, rownames=['True Label'], colnames=['Predicted Label'], margins=True)

print cm

Predicted Label    0   1  All
True Label                   
0                199  17  216
1                 25  44   69
All              224  61  285
```

sensitivity = 44/(25+44) = 64%

specificity = 199/(199 + 17) = 92%

The sensitivity and specificity were comprable to the Decision Tree model.

####Model Evaluation
I used the same metrics to compare KNN to the Decision Tree and Naive Bayes models.

```
accuracy_scores_KNN = cross_val_score(KNN, explanatory_df, response_series, cv=10, scoring='accuracy', n_jobs = -1)

print accuracy_scores_KNN.mean()
84%

# Cohen's Kappa
mean_accuracy_score_KNN = accuracy_scores_KNN.mean()

kappa_KNN = (mean_accuracy_score_KNN - largest_class_percent_of_total) / (1-largest_class_percent_of_total)

print kappa_KNN
.312


# F1 score
f1_scores_KNN = cross_val_score(KNN, explanatory_df, response_series, cv=10, scoring='f1', n_jobs = -1)

print f1_scores_KNN.mean()
.601

# ROC
roc_scores_KNN = cross_val_score(KNN, explanatory_df, response_series, cv=10, scoring='roc_auc', n_jobs = -1)

print roc_scores_KNN.mean()
.830
```

The K Nearest Neighbor model was the best at predicting Hall of Fame induction by all metrics except F1 scores (which was only slightly less than the Decision Tree model).

I then printed a ROC curve of all three models.

```
# ROC curve
predicted_probs_cart = pandas.DataFrame(decision_tree.predict_proba(xTest))
predicted_probs_NB = pandas.DataFrame(naive_bayes_classifier.predict_proba(xTest))
predicted_probs_KNN = pandas.DataFrame(KNN.predict_proba(xTest))

from sklearn import metrics
import matplotlib.pyplot as plt

fpr_cart, tpr_cart, thresholds_cart = metrics.roc_curve(yTest, predicted_probs_cart[1])
fpr_NB, tpr_NB, thresholds_NB = metrics.roc_curve(yTest, predicted_probs_NB[1])
fpr_KNN, tpr_KNN, thresholds_KNN = metrics.roc_curve(yTest, predicted_probs_KNN[1])

plt.figure()
plt.plot(fpr_cart, tpr_cart, color = 'r')
plt.plot(fpr_KNN, tpr_KNN, color = 'b')
plt.plot(fpr_NB, tpr_NB, color = 'g')
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
```

![ROC](https://github.com/bbalin12/DAT5_BOS_students/blob/master/kimkraunz/Class_8_HW_DecisionTree/ROC.png)

The KNN and Decision Tree models both show fairly decent ROC curves.

####Conclusions

For this data, the KNN model was the best at predicting Hall of Fame induction.  The Decision Tree model was decent as well but Naive Bayes was a fairly poor predictor of Hall of Fame induction.


