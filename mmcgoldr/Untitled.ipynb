{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3 as sq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.cross_validation import cross_val_score as cv\n",
    "from sklearn.grid_search import GridSearchCV as gscv\n",
    "from sklearn.feature_selection import RFECV as rfe\n",
    "from sklearn import linear_model as lm\n",
    "from statsmodels.formula.api import logit\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrix, dmatrices\n",
    "import matplotlib.pylab as plt\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD USER-DEFINED FUNCTIONS FOR DATA MANIPULATION-----------------------------\n",
    "\n",
    "#convert low-freq categorical feature values to 'Other'\n",
    "def cleanup_data(df, cutoffPercent = .01):\n",
    "    for col in df:\n",
    "        sizes = df[col].value_counts(normalize = True)\n",
    "        values_to_delete = sizes[sizes<cutoffPercent].index\n",
    "        df[col].ix[df[col].isin(values_to_delete)] = \"Other\"\n",
    "    return df\n",
    "\n",
    "#binazrize catergoical feature values into individual variables\n",
    "def get_binary_values(data_frame):\n",
    "    \"\"\"encodes categorical features in Pandas.\"\"\"\n",
    "    all_columns = pd.DataFrame(index = data_frame.index)\n",
    "    for col in data_frame.columns:\n",
    "        data = pd.get_dummies(data_frame[col], prefix=col.encode('ascii', 'replace'))\n",
    "        all_columns = pd.concat([all_columns, data], axis=1)\n",
    "    return all_columns\n",
    "\n",
    "#find and remove variables with zero variance\n",
    "def find_zero_var(df):\n",
    "    \"\"\"finds columns in the dataframe with zero variance -- ie those\n",
    "        with the same value in every observation.\n",
    "    \"\"\"\n",
    "    toKeep = []\n",
    "    toDelete = []\n",
    "    for col in df:\n",
    "      if len(df[col].value_counts()) > 1:\n",
    "         toKeep.append(col)\n",
    "      else:\n",
    "        toDelete.append(col)      \n",
    "    return {'toKeep':toKeep, 'toDelete':toDelete}\n",
    "    \n",
    "#find and remove variables with perfect correlation\n",
    "def find_perfect_corr(df):\n",
    "    \"\"\"finds columns that are eother positively or negatively perfectly \n",
    "        correlated (with correlations of +1 or -1), and creates a dict that \n",
    "        includes which columns to drop so that each remaining column is independent\n",
    "    \"\"\"\n",
    "    corrMatrix = df.corr()\n",
    "    corrMatrix.loc[:,:] = np.tril(corrMatrix.values, k = -1)\n",
    "    already_in = set()\n",
    "    result = []\n",
    "    for col in corrMatrix:\n",
    "        perfect_corr = corrMatrix[col][abs(np.round(corrMatrix[col],10)) == 1.00].index.tolist()\n",
    "        if perfect_corr and col not in already_in:\n",
    "            already_in.update(set(perfect_corr))\n",
    "            perfect_corr.append(col)\n",
    "            result.append(perfect_corr)\n",
    "    toRemove = []\n",
    "    for item in result:\n",
    "        toRemove.append(item[1:(len(item)+1)])\n",
    "        toRemove = sum(toRemove, [])\n",
    "    return {'corrGroupings':result, 'toRemove':toRemove}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql: select h.*, \n  b.b_atbat, b.b_runs, b.b_hits, b.b_hruns, b.b_stbas, b.b_strik,\n  p.p_wins, p.p_loss, p.p_shout, p.p_saves, p.p_eruns, p.p_stout, \n  f.f_puts, f.f_assis, f.f_dplay, f.f_pass, o.pos, t.teamid\nfrom \n  (select playerid, max(case when inducted = 'Y' then 1 else 0 end) as inducted, max(yearid) as year\n   from halloffame where category = 'Player' group by playerid) h\nleft outer join \n  (select playerid, sum(ab) as b_atbat, sum(r) as b_runs, sum(h) as b_hits, \n    sum(hr) as b_hruns, sum(sb) as b_stbas, sum(so) as b_strik\n  from batting group by playerid) b on h.playerid = b.playerid\nleft outer join\n  (select playerid, sum(w) as p_wins, sum(l) as p_loss, sum(sho) as p_shout,\n    sum(sv) as p_saves, sum(er) as p_eruns, sum(so) as p_stout\n  from pitching group by playerid) p on h.playerid = p.playerid\nleft outer join\n  (select playerid, sum(po) as f_puts, sum(a) as f_assis, sum(dp) as f_dplay, sum(pb) as f_pass \n  from fielding group by playerid) f on h.playerid = f.playerid\nleft outer join\n  (select * from dominant_position_per_player) o on h.playerid = o.playerid\nleft outer join\n  (select * from dominant_team_per_player) t on h.playerid = t.playerid\n;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ba8e11df1e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m ;\"\"\"\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#close connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns)\u001b[0m\n\u001b[1;32m    386\u001b[0m         return pandas_sql.read_sql(\n\u001b[1;32m    387\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             coerce_float=coerce_float, parse_dates=parse_dates)\n\u001b[0m\u001b[1;32m    389\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPandasSQLLegacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                  parse_dates=None):\n\u001b[1;32m   1021\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetchall_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Execution failed on sql: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     def read_sql(self, sql, index_col=None, coerce_float=True, params=None,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/sql.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql: select h.*, \n  b.b_atbat, b.b_runs, b.b_hits, b.b_hruns, b.b_stbas, b.b_strik,\n  p.p_wins, p.p_loss, p.p_shout, p.p_saves, p.p_eruns, p.p_stout, \n  f.f_puts, f.f_assis, f.f_dplay, f.f_pass, o.pos, t.teamid\nfrom \n  (select playerid, max(case when inducted = 'Y' then 1 else 0 end) as inducted, max(yearid) as year\n   from halloffame where category = 'Player' group by playerid) h\nleft outer join \n  (select playerid, sum(ab) as b_atbat, sum(r) as b_runs, sum(h) as b_hits, \n    sum(hr) as b_hruns, sum(sb) as b_stbas, sum(so) as b_strik\n  from batting group by playerid) b on h.playerid = b.playerid\nleft outer join\n  (select playerid, sum(w) as p_wins, sum(l) as p_loss, sum(sho) as p_shout,\n    sum(sv) as p_saves, sum(er) as p_eruns, sum(so) as p_stout\n  from pitching group by playerid) p on h.playerid = p.playerid\nleft outer join\n  (select playerid, sum(po) as f_puts, sum(a) as f_assis, sum(dp) as f_dplay, sum(pb) as f_pass \n  from fielding group by playerid) f on h.playerid = f.playerid\nleft outer join\n  (select * from dominant_position_per_player) o on h.playerid = o.playerid\nleft outer join\n  (select * from dominant_team_per_player) t on h.playerid = t.playerid\n;"
     ]
    }
   ],
   "source": [
    "#GET DATA FROM SQL DB INTO PANDAS DATA FRAME-----------------------------------\n",
    "\n",
    "#reconnect to SQLite DB\n",
    "conn = sq.connect('/Users/harishkashyap/Documents/SQLite/lahman2013.sqlite')\n",
    "\n",
    "#get position, dominant team and performance stats\n",
    "query2 = \"\"\"select h.*, \n",
    "  b.b_atbat, b.b_runs, b.b_hits, b.b_hruns, b.b_stbas, b.b_strik,\n",
    "  p.p_wins, p.p_loss, p.p_shout, p.p_saves, p.p_eruns, p.p_stout, \n",
    "  f.f_puts, f.f_assis, f.f_dplay, f.f_pass, o.pos, t.teamid\n",
    "from \n",
    "  (select playerid, max(case when inducted = 'Y' then 1 else 0 end) as inducted, max(yearid) as year\n",
    "   from halloffame where category = 'Player' group by playerid) h\n",
    "left outer join \n",
    "  (select playerid, sum(ab) as b_atbat, sum(r) as b_runs, sum(h) as b_hits, \n",
    "    sum(hr) as b_hruns, sum(sb) as b_stbas, sum(so) as b_strik\n",
    "  from batting group by playerid) b on h.playerid = b.playerid\n",
    "left outer join\n",
    "  (select playerid, sum(w) as p_wins, sum(l) as p_loss, sum(sho) as p_shout,\n",
    "    sum(sv) as p_saves, sum(er) as p_eruns, sum(so) as p_stout\n",
    "  from pitching group by playerid) p on h.playerid = p.playerid\n",
    "left outer join\n",
    "  (select playerid, sum(po) as f_puts, sum(a) as f_assis, sum(dp) as f_dplay, sum(pb) as f_pass \n",
    "  from fielding group by playerid) f on h.playerid = f.playerid\n",
    "left outer join\n",
    "  (select * from dominant_position_per_player) o on h.playerid = o.playerid\n",
    "left outer join\n",
    "  (select * from dominant_team_per_player) t on h.playerid = t.playerid\n",
    ";\"\"\"\n",
    "\n",
    "df = pd.read_sql(query2, conn)\n",
    "\n",
    "#close connection\n",
    "conn.close()\n",
    "\n",
    "#check data\n",
    "df.head()\n",
    "df.tail()\n",
    "df.shape\n",
    "\n",
    "#split data before and on/after year 2000 (training vs future predictions)\n",
    "pre2000 = df[df.year < 2000.00]\n",
    "post2000 = df[df.year >= 2000.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
